from __future__ import print_function

"""
CanyonOptimizer.py
Eric Poppenheimer
January 2019

I am having a lot of trouble using TFRT to optimize achromatic prism doublets.  As far as I can tell, everything is 
working correctly, I think the problem is just that the optimization problem is not very well suited to any of the 
optimization algorithms I have available.  I imagine the parameter space of this problem as looking like a canyon,
with extremely steep walls that necessitate a very small step size that form a canyon whose bottom is extremely 
shallow, and so very difficult to traverse without a very large step size.  So I shall try to write an optimizer that
I think will do a better job on this kind of problem.

This optimizer is based on gradient descent with momentum.  It keeps track of a single float that represents the 
quality of the solution (probably just something like reduce_mean(error) ) and adjusts what it is doing based on this
value.  When the error from the previous step decreases, we incease the step size.  If the error increases, we 
immediately decrease the step size, cancel all velocity, and undo the previous parameter update.

I am not going to inheret from the tf.optimizer class as I perhaps should, because right now I don't want to go to the
hassle of making this class as sophisticated as those ones.

"""

import tensorflow as tf
import numpy as np


class CanyonOptimizer(object):
    def __init__(
        self,
        baseStepSize=1.0,
        momentum=0.95,
        stepSizeGrowthFactor=1.1,
        stepSizeShrinkFactor=0.5,
    ):
        # The four parameters may be floats, tensors, or placeholders.  The only restriction is that they should be
        # scalars.
        #
        # baseStepSize: The initial value for the step size, equivalent to learning rate in other algorithms, but I am
        #   renaming it because I feel like this is a more descriptive name.
        # momentum: The fraction of the previous step to add to the gradient at the current location.  Should be
        #   0<momentum<1.0.
        # stepSizeGrowthFactor: The base step size will grow by this factor with each sucessful step
        # stepSizeShrinkFactor: Whenever we overshoot and the error increases, decrease the step size by this factor

        self.baseStepSize = baseStepSize
        self.momentum = momentum
        self.stepSizeGrowthFactor = stepSizeGrowthFactor
        self.stepSizeShrinkFactor = stepSizeShrinkFactor

        """# lists that hold TF variables generated by this class, exposed so that they can be initialized
        self.allVariables = []
        self.uninitializedVariables = []"""

        # A dictionary that will hold parameters for individual instances of optimization problems generated by this
        # class
        self._instanceParameters = {}

    """def initializeVariables(self, session):
        # Initializes all of the variables created by this class when fed a session.  Will only initialize them once,
        # as afterward they are removed from the uninitializedVariables list
        session.run([var.initializer for var in self.uninitializedVariables])
        self.uninitializedVariables = []"""

    def compute_gradients(self, error, var_list):
        # Pretty much does nothing besides call tf.gradients, but is included for semi-compatability with the tf built
        # in optimizers.
        #
        # error: The tensor (may be of any shape) to be minimized, whose gradients will be calculated.
        # var_list: The list of variables with respect to who the gradient will be calculated.  These are the
        #   parameters to adjust.  Not optional, like with the built in optimizer classes.
        if type(var_list) is not list:
            var_list = [var_list]
        return [(tf.gradients(error, variable), variable) for variable in var_list]

    def getUpdateStep(self, grads_and_vars, quality):
        # I tried to write apply_gradients to comply with the way TF does optimizers, but this problem doesn't seem to
        # quite lend itself to the graph style of programming, so I am backtracking.  This function constructs some
        # tf graph members to help it do its job, and then returns a function that applies the update operations
        # when called.
        #
        # grads_and_vars: A list of gradient, variable pairs, as given by compute_gradients.
        # quality: This should be a scalar value that judges how good the current solution is, and determines when to
        #   adjust the parameters, as described at the top.  This should probably be either the error, if it is a
        #   scalar, or reduce_mean(error) otherwise.
        # return: A function that takes two arguments, a TF session, and a feed_dict needed to evaluate
        #   the gradient, and performs all of the logic needed to execute a single training step.

        try:
            shape = quality.shape
        except:
            raise ValueError(
                "CanyonOptimizer.apply_gradients: unable to retrieve shape of quality"
            )
        if quality.shape != ():
            raise ValueError("CanyonOptimizer.apply_gradients: quality not a scalar")

        # create a list that will hold step functions for each individual variable
        stepFunctionList = []

        for gradient, variable in grads_and_vars:
            # create a space in _instanceParameters to hold the local parameters for this optimization instance
            parameters = self._instanceParameters[variable.name[:-2]] = {}

            # reshape the gradient to match the variable, just in case, to catch any cases where dimensions of size 1
            # were added or subtracted.
            gradient = tf.reshape(gradient, tf.shape(variable))

            # variable to hold the quality before running this iteration (quality from last iteration, or initial
            # value).
            parameters["previousQuality"] = np.inf

            # variable to hold the old point in parameter space
            parameters["previousValue"] = np.zeros(variable.shape, dtype=np.float64)

            # variable to hold the step size factor
            parameters["stepSizeFactor"] = 1.0

            # variable to hold the previous step (encodes the velocity of the descent)
            parameters["previousStep"] = np.zeros(
                shape=gradient.shape, dtype=np.float64
            )

            # just a convenient tool to use to kill the momentum, a set of zeros of the correct shape
            parameters["zeroStep"] = parameters["previousStep"]

            # op that assigns a new value to the variable
            variablePlaceholder = tf.placeholder(
                tf.float64,
                shape=variable.shape,
                name=variable.name[:-2] + "placeholder",
            )
            assign = tf.assign(variable, variablePlaceholder)

            def stepFunction(session, fd, p=parameters):

                # save the old values
                p["previousValue"], p["previousQuality"] = session.run(
                    [variable, quality], feed_dict=fd
                )

                # compute the step size
                stepSize = self.baseStepSize * p["stepSizeFactor"]

                # take the current step.  Attempting to use Nesterov accellerated gradient.
                f = fd
                f[variablePlaceholder] = (
                    p["previousValue"] + self.momentum * p["previousStep"]
                )
                session.run(assign, feed_dict=f)

                grad, val = session.run([gradient, variable], feed_dict=fd)

                f = fd
                f[variablePlaceholder] = val - stepSize * grad
                session.run(assign, feed_dict=f)

                # store the step we just took
                p["previousStep"] = self.momentum * p["previousStep"] - stepSize * grad

                # get the new quality, and compare it to the previous quality
                newQuality = session.run(quality, feed_dict=fd)
                if newQuality < p["previousQuality"]:
                    # if quality decreased, we are on track.  Increase the step size and proceed
                    p["stepSizeFactor"] *= self.stepSizeGrowthFactor
                else:
                    # otherwize, quality increased, so we should go back to the last value, kill the momentum, and
                    # reduce the step size
                    print(
                        "step in wrong direction.  StepSizeFactor: ",
                        p["stepSizeFactor"],
                    )
                    session.run(
                        assign, feed_dict={variablePlaceholder: p["previousValue"]}
                    )
                    p["previousStep"] = p["zeroStep"]
                    p["stepSizeFactor"] *= self.stepSizeShrinkFactor

            stepFunctionList.append(stepFunction)

        # Build a function that just calls each of the functions generated for each individual variable
        def fullStep(session, fd):
            for f in stepFunctionList:
                f(session, fd)

        return fullStep

    """def apply_gradients(self, grads_and_vars, quality):
        # Actually constructs the graph that computes the parameter updates, and returns an op that runs them.  Some 
        # time after this function is called, you should call initializeVariables to initialize the variables generated
        # in this call (though you can also use the built in global variables initializer to do this).
        #
        # grads_and_vars: A list of gradient, variable pairs, as given by compute_gradients.
        # quality: This should be a scalar value that judges how good the current solution is, and determines when to
        #   adjust the parameters, as described at the top.  This should probably be either the error, if it is a 
        #   scalar, or reduce_mean(error) otherwise.        
        
        try:
            shape = quality.shape
        except:
            raise ValueError("CanyonOptimizer.apply_gradients: unable to retrieve shape of quality")
        if quality.shape != ():
            raise ValueError("CanyonOptimizer.apply_gradients: quality not a scalar")
        
        applyOps = []
        for gradient, variable in grads_and_vars:
            with tf.variable_scope(variable.name[:-2]) as scope:
                gradient = tf.reshape(gradient, tf.shape(variable))
                
                # variable to hold the quality before running this iteration (quality from last iteration, or initial 
                # value).
                previousQuality = tf.get_variable("previousQuality", dtype=tf.float64, 
                    initializer=tf.constant(np.inf, dtype=tf.float64))
                self.uninitializedVariables.append(previousQuality)
                previousQuality = tf.assign(previousQuality, quality)
                
                # variable to hold the old point in parameter space
                previousValue = tf.get_variable("previousValue", shape=variable.shape, dtype=tf.float64,
                    initializer=tf.zeros_initializer)
                self.uninitializedVariables.append(previousValue)
                previousValue = tf.assign(previousValue, variable)
                
                # variable to hold the step size factor
                stepSizeFactor = tf.get_variable("stepSizeFactor", shape=(), dtype=tf.float64,
                    initializer=tf.ones_initializer)
                self.uninitializedVariables.append(stepSizeFactor)
                
                stepSize = self._baseStepSize * stepSizeFactor
                
                # variable to hold the previous step (encodes the velocity of the descent)
                previousStep = tf.get_variable("previousStep", shape=gradient.shape, dtype=tf.float64,
                    initializer=tf.zeros_initializer)
                self.uninitializedVariables.append(previousStep)
                    
                # take the current step.  The second control dependency context manager is my attempt to implement 
                # Nesterov accellerated gradient, though I don't really know if I can test that this is actually doing 
                # it properly.
                with tf.control_dependencies([previousQuality, previousValue]):
                    updatedVariable1 = tf.assign_add(variable, self._momentum * previousStep)
                with tf.control_dependencies([updatedVariable1]):
                    updatedVariable2 = tf.assign_sub(variable, stepSize * gradient)
                
                # perform the update, and now check whether the update improved quality.  If not, revert and adjust
                # the step size
                
                def qualityGood():
                    # these tensors will be run if the solution improved (quality decreased) from this step 
                    # compared to previousQuality
                    newStepSizeFactor = stepSizeFactor * self._stepSizeGrowthFactor
                    return newStepSizeFactor
                
                def qualityBad():
                    # these tensors will be run if the solution worsened (quality increased) from this step 
                    # compared to previousQuality 
                    killMomentum = tf.assign(previousStep, tf.zeros_like(previousStep))
                    resetValue = tf.assign(variable, previousValue)
                    p1 = tf.print("reverting")
                    
                    with tf.control_dependencies([p1, killMomentum, resetValue]):
                        newStepSizeFactor = stepSizeFactor * self._stepSizeShrinkFactor
                    return newStepSizeFactor
                    
                with tf.control_dependencies([updatedVariable2]):
                    newStepSizeFactor = tf.cond(quality < previousQuality, qualityBad, qualityGood)
                    updateStepSizeFactor = tf.assign(stepSizeFactor, newStepSizeFactor)
                    
                
                assignPreviousStep = tf.assign(previousStep, self._momentum * previousStep - stepSize * gradient)
                applyOps.append(updateStepSizeFactor)
                applyOps.append(assignPreviousStep)
                
                self.allVariables += self.uninitializedVariables
        return tf.group(applyOps)
    """
