"""
Graph-like utilities for the vertices of meshes.  Tools for smoothing the gradient of a 3D
parametric surface.

These functions generate data structures that represent directed acyclic graphs that
describe connections between vertices of a mesh.  They are intended to help construct
sensible gradient cumulative summation matrices to help prevent parametric meshes from
developing rough surfaces.  These functions tend to produce lists of set.  Each set in the 
list corresponds to one vertex in the mesh.  And each element in each set represents
connections between that vertex and others in the mesh.

All the functions are public, but most users will only need to call gradient_accumulator.

Please be aware that this module does NOT use tensorflow.  It uses numpy instead.
"""

import itertools
import math

import numpy as np
import pyvista as pv
from scipy.interpolate import griddata

PI = math.pi

# =========================================================================================

def gradient_accumulator_1p(mesh, origin=(0, 0, 0)):
    """
    Version in which children have only 1 parent.
    
    Builds a smoothing gradient_accumulator matrix for a mesh, around a starting point.
    
    Origin should be a point (3-tuple or 3-vector) that ideally sits at the center of the
    mesh, or wherever you think is a good place to build the accumulator around.  This
    function will find the closest point in the mesh to the origin point, and build the
    accumulator around that point.
    
    Parameters
    ----------
    mesh : pyvista PolyData
        The pyvista mesh that was used to paramatrize the parametric surface.
    origin : 3-tuple / 3-vector.
    
    Returns
    -------
    accumulator : np.array
        A square array whose side length is equal to the number of points in the mesh.
        This matrix can be left-multiplied with the gradient generated by the optimizer
        to perform smoothing gradient accumulation that will hopefully prevent the surface
        from becomming too rough due to uneven training.  The result of this left-multiply
        can be used to update the parameters.
    relationship_data : dict
        Holds the four relationship graphs generated in the course of calculating the
        accumulator.  These are convenient if you also want to use neighbor smoothing, and
        can be passed to that function to save computation time.  The dict has four keys for 
        the four graphs: "decendant", "child", "parent", and "ancestor".  It also has one
        a key, "top_parent", the index of the point that was chosen as the origin of the
        accumulator, and a key "unique_edges" for the set of unique edges in the mesh.
    
    """
    origin = np.array(origin, dtype=np.float64)
    top_parent = get_closest_point(mesh, origin)
    unique_edges = get_unique_edges(mesh)
    
    out_dict = {"top_parent": top_parent, "unique_edges": unique_edges}
    out_dict["descendant"], out_dict["child"], out_dict["parent"], out_dict["ancestor"] = \
        find_all_relationships(top_parent, mesh, unique_edges)
        
    accumulator = connections_to_array(out_dict["descendant"])
    return accumulator, out_dict

# =========================================================================================

def get_closest_point(mesh, target):
    """
    Gets the index of the point in the mesh closest (in cartesian distance) to traget.
    """
    distance = np.sum((mesh.points - target)**2, axis=1)
    return np.argmin(distance)

# -----------------------------------------------------------------------------------------
    
def get_unique_edges_1p(mesh):
    """
    Given a pyvista mesh, generate a set of 2-element frozenset that encodes every
    edge (line between vertices) in the mesh.  The edges are unique.  Elements of edges are 
    indices into the mesh's points.
    """
    faces = mesh.faces
    faces = np.reshape(faces, (-1, 4))
    
    # these are each side of each triangle
    a = faces[:,1:3]
    b = faces[:,2:4]
    c = faces[:,1:4:2]
    all_edges = np.concatenate([a, b, c], axis=0)
    
    # use set as a convenient way of removing duplicates
    deduplicated_edges = {frozenset(e) for e in all_edges}
    return deduplicated_edges
    
# -----------------------------------------------------------------------------------------

def neighbors_from_edges(start, edges):
    """
    Finds all points adjacent to the parent point.  Parent is the index of a vertex, and
    edges is a uniqueified set of the indices of each edge.
    """
    neighbor_list = [edge for edge in edges if start in edge]
    neighbor_set = set(
        [neighbor for frozen_neighbor in neighbor_list for neighbor in frozen_neighbor]
    )
    
    return neighbor_set - set([start])
    
# -----------------------------------------------------------------------------------------

def neighbors_from_faces(point, faces):
    """
    Returns a set of all points that are next to point.  Uses faces (formatted as a list of 
    sets) to compute this instead of edges.
    """
    out = set()
    for face in faces:
        if point in face:
            out |= face
    out.discard(point)
    return out

# -----------------------------------------------------------------------------------------

def find_all_relationships_1p(top_parent, mesh, edges):
    """
    Version in which children have only 1 parent.
    
    Given a mesh, and top_parent, the index of a point in the mesh at which to start,
    generates a list of sets, one for each point in the mesh, that contains the indices of
    each point considered a child of that point.  If a set in the output is empty, that point
    is a lowest-level child.
    
    The first returns is a list of all decendants, for each vertex, and the second return
    is a list of all direct children, for each vertex.
    """
    points = mesh.points
    point_count = points.shape[0]
    top_parent_position = np.array(points[top_parent])
    all_children = set(range(point_count))
    child_list = [set()] * point_count
    parent_list = [set()] * point_count
    ancestor_list = [set()] * point_count
    
    # claim the top parent
    unclaimed_children = all_children - set([top_parent])
    
    # find all children (breadth first)
    queue = [top_parent]
    reverse_queue = []
    while queue:
        parent = queue.pop(0)
        reverse_queue.append(parent)
        
        # compute the children of parent
        parents_children = neighbors_from_edges(parent, edges) & unclaimed_children
        unclaimed_children.difference_update(parents_children)
        child_list[parent] = parents_children
        
        # queue up the children to have their children found
        for child in parents_children:
            queue.append(child)
            parent_list[child] = set([parent])
            ancestor_list[child] = parent_list[child] | ancestor_list[parent]
            
        #sort the queue by distance from the top parent
        queue_points = np.take(points, queue, axis=0)
        distance = np.sum((queue_points - top_parent_position)**2, axis=1)
        queue = list(np.take(queue, np.argsort(distance)))
        
    # reverse_queue gets filled with each node that gets any children, in the order
    # that they are filled.  Go through it in reverse, to accumulate all descendants.
    descendant_list = child_list.copy()
    for target in reverse_queue[::-1]:
        for child in child_list[target]:
            descendant_list[target] = descendant_list[target] | descendant_list[child]
    
    return descendant_list, child_list, parent_list, ancestor_list

# -----------------------------------------------------------------------------------------

def get_faces_as_sets(mesh):
    return [set(face) for face in np.reshape(mesh.faces, (-1, 4))[:,1:]]

# -----------------------------------------------------------------------------------------

def find_generations(top_parent, mesh):
    """
    Breaks the points in mesh into generations, starting with top_parent.  The first
    generation contains only top_parent, the second contains top_parent's neighbors, and
    sucessive generations contain sucessive neighbors that haven't already been accounted
    for.
    """
    generations = [set([top_parent])]
    faces = get_faces_as_sets(mesh)
    point_count = mesh.points.shape[0]
    remaining_points = set(range(point_count)) - generations[0]
    
    print(f"remaining points: {remaining_points}")
    
    while remaining_points:
        neighbors = set()
        for point in generations[-1]:
            neighbors |= neighbors_from_faces(point, faces)
        neighbors &= remaining_points
        remaining_points -= neighbors
        generations.append(neighbors)
    
    return generations

# =========================================================================================

def raw_mesh_parametrization_tools(mesh, top_parent):
    """
    Raw version of the function, which returns extra information for debugging.
    
    Determines which of a face's vertices that face is allowed to update, in a way that
    tries to minimize competition between adjacent faces.
    """
    face_sets = get_faces_as_sets(mesh)
    face_count = len(face_sets)
    point_count = mesh.points.shape[0]
    faces = np.reshape(mesh.faces, (-1, 4))[:,1:]
    face_movable_vertices = [set()] * face_count
    faces_to_visit = set(range(face_count))
    active_edge = set([top_parent])
    last_edge = set()
    available_vertices = set(range(point_count))
    vertex_parents = [set()] * point_count
    vertex_ancestors = [set()] * point_count
    missed_vertices = set(range(point_count))
            
    #counter = 0 # to prevent infinite loops
    while faces_to_visit:
        #counter += 1
        #if counter >= 5:
        #    break
        
        next_active_edge = set() 
        faces_just_visited = set()   
        available_vertices -= active_edge
        # work on face_movable_vertices
        for face in faces_to_visit:
            for vertex in active_edge:
                if vertex in face_sets[face]:
                    movable_vertices = face_sets[face] & available_vertices
                    next_active_edge |= movable_vertices
                    face_movable_vertices[face] = movable_vertices
                    faces_just_visited.add(face)
                    
        # work on vertex ancestors
        # this may miss vertices along the edge after all faces have been depleted.
        for vertex in active_edge:
            missed_vertices.remove(vertex)
            vertex_parents[vertex] = neighbors_from_faces(vertex, face_sets) & last_edge
            vertex_ancestors[vertex] = vertex_parents[vertex].copy()
            for parent in vertex_parents[vertex]:
                vertex_ancestors[vertex] |= vertex_ancestors[parent]
        
        # step the sets to the next edge
        faces_to_visit -= faces_just_visited
        last_edge = active_edge
        active_edge = next_active_edge
    
    # take care of any missed vertices    
    for vertex in missed_vertices:
        vertex_parents[vertex] = neighbors_from_faces(vertex, face_sets) - missed_vertices
        vertex_ancestors[vertex] = vertex_parents[vertex].copy()
        for parent in vertex_parents[vertex]:
            vertex_ancestors[vertex] |= vertex_ancestors[parent]
    
    return (
        face_movable_vertices,
        vertex_ancestors,
        vertex_parents,
        missed_vertices
    )

# -----------------------------------------------------------------------------------------

def mesh_parametrization_tools(mesh, top_parent, active_vertices=None):
    """
    Determines which of a face's vertices that face is allowed to update, in a way that
    tries to minimize competition between adjacent faces.
    
    Parameters
    ----------
    mesh : pyvista mesh
        The mesh that is being used to parametrize the surface.
    top_parent : int
        The index of the vertex to base the parametrization around.  Typically
        found via get_closest_point()
    active_vertices : 1D iterable of ints, optional
        The vertices that will possess parameters.  These will be used to
        cut down the accumulator to the shape the parameters will actually have,
        for boundaries that have a reduced number of parameters.  Defaults to
        None, in which case the accumulator is sized to the total number
        of vertices in the mesh.
        
    Returns
    -------
    vertex_update_map : (n, 3) np boolean array
        This array has a row for each face in the mesh, and the values in the columns
        are True wherever a face is allowed to move one of its vertices.  Should be fed
        to your TriangleBoundary.
    gradient_accumulator : (n, n) np float64 array
        This array can be left-multiplied onto the gradient to accomplish an accumulating
        effect; when one vertex is moved others connected to it will also get moved, to
        reduce faces competing with each other.
    
    """
    face_movable_vertices, vertex_ancestors, vertex_parents, missed_vertices = \
        raw_mesh_parametrization_tools(mesh, top_parent)

    vertex_update_map = movable_to_updatable(mesh, face_movable_vertices)
    accumulator = connections_to_array(vertex_ancestors)

    if active_vertices is not None:
        kept_vertices = [i for i in range(accumulator.shape[0])
                         if i in active_vertices]
        accumulator = accumulator[:, kept_vertices][kept_vertices, :]

    return vertex_update_map, accumulator

# =========================================================================================

def gaussian_weights(sigma, count):
    """
    Generates a list of values calculated with a gaussian, for use with the smoothing tool.
    Not normalized, because the smoother does that on its own.
    """
    x = np.arange(count) / sigma
    return np.exp(-.5*x**2)

# -----------------------------------------------------------------------------------------

def mesh_smoothing_tool(mesh, weights, active_vertices=None):
    """
    Tool for smoothing a mesh (that works on the mesh's parameters).
    
    This tool generates a matrix that has the effect of smoothing a mesh when left-
    multiplied with the parameters.
    
    Parameters
    ----------
    mesh : pyvista mesh
        The mesh that is being used to parametrize the surface.
    weights : list of number
        A list that describes the relative weight to give to each generation of neighbors.
        Should have at least two elements, or no smoothing will occur.  The first number
        relates to the point itself, the second number to the points neighbors, the third to
        the neighbors' neighbors, and so on.  Does not need to be normalized, as this 
        function will automatically account for that, given that different points can have
        different numbers of neighbors.
        
        Example: if weights = [x, y, z] and for N = x + y + z, each vertex on the mesh will
        keep x/N of its magnitude, y/N of the magnitude will be distributed evenly across
        all neighbors, and z/N value will be distributed evenly across all neighbors' 
        neighbors.

    active_vertices : 1D iterable of ints, optional
        The vertices that will possess parameters.  These will be used to
        cut down the smoother to the shape the parameters will actually have,
        for boundaries that have a reduced number of parameters.  Defaults to
        None, in which case the smoother is sized to the total number
        of vertices in the mesh.
    
    Returns
    -------
    smoother : (n, n) np float64 array
        This array can be left-multiplied onto the gradient to accomplish a smoothing
        effect on the mesh - sharp features will be spread out to make the surface more
        uniform.
    """
    face_sets = get_faces_as_sets(mesh)
    point_count = mesh.points.shape[0]
    neighbor_depth = len(weights)
    nth_neighbors = [None] * point_count
    weights = weights / np.sum(weights)
    
    # construct nth_neighbors, which is a list of list of sets.  The first list
    # indexes points/vertices in the mesh, the second list indexes sucessive sets of
    # neighbors, with the first list being the zero-th order neighbor, (the point itself)
    # and each set contains the index of the points that are that level of neighbor from
    # each point.
    for point in range(point_count):
        nth_neighbors[point] = [set([point])]
        taken_neighbors = nth_neighbors[point][0].copy()
        current_edge = nth_neighbors[point][0].copy()
        for neighbor_order in range(1, neighbor_depth):
            new_neighbors = set()
            for edge_point in current_edge:
                new_neighbors |= neighbors_from_faces(edge_point, face_sets)
            new_neighbors -= taken_neighbors
            
            nth_neighbors[point].append(new_neighbors)
            current_edge = new_neighbors
            taken_neighbors |= new_neighbors

    # now build the smoothing matrix
    smoother = np.zeros((point_count, point_count), dtype=np.float64)
    for point in range(point_count):
        for neighbor_order in range(neighbor_depth):
            neighbors = nth_neighbors[point][neighbor_order]
            weight = weights[neighbor_order] / len(neighbors)
            smoother[point, list(neighbors)] = weight

    if active_vertices is not None:
        kept_vertices = [i for i in range(smoother.shape[0])
                         if i in active_vertices]
        smoother = smoother[:, kept_vertices][kept_vertices, :]
        
    return smoother

# =========================================================================================

def get_flat_initial(mesh, axis=0):
    """
    Separates one dimension out of a mesh, replacing the values in that dimension with zero
    and returns the removed values as a separate 1D array.
    
    This function is useful for setting up the initial condition for a parametric optic.  It 
    is convenient to have the zero point mesh for a parametric optic be planar in order to
    set up some kinds of constraints.  So if you want to parametrize an optic relative to a 
    plane but also start with a non-planar initial condition for it, this function will
    flatten the mesh and return an array that can be used to initialize the parameters.
    
    Parameters
    ----------
    mesh : pyvista mesh
        The mesh to flatten.  This function will alter the mesh you give it, so make a copy
        before if you need it.
    axis : int, optional
        The index of the axis you want to flatten out.  Must be 0, 1, or 2, for the x, y, or z
        dimension.  Defaults to 0 for the x dimension.
        
    Returns
    -------
    initials : 1D np.array
        The initial values use to re-inflate the given mesh to it's original shape.
        
    """
    if axis not in {0, 1, 2}:
        raise ValueError("get_flat_initial: axis must be in {0, 1, 2}.")
    initial_parameter = mesh.points[:,axis].copy()
    mesh.points[:,axis] = 0.0
    return initial_parameter

# =========================================================================================

def movable_to_updatable(mesh, face_movable_vertices):
    """
    Converts a list of sets that dictates which vertices each face is allowed to move into
    a boolean array that can be used to mask away updates.
    """
    face_updates = []
    face_count = len(face_movable_vertices)
    faces = np.reshape(mesh.faces, (-1, 4))[:,1:]
    
    for face in range(face_count):
        face_updates.append(
            [True if vertex in face_movable_vertices[face] else False \
                for vertex in faces[face]
            ]
        )
    
    # some faces may have no movable vertices.  We can't really allow this, so instead I
    # am going to allow these to move all of their vertices
    orphaned_count = 0
    for face in range(face_count):
        if not np.any(face_updates[face]):
            orphaned_count += 1
            face_updates[face] = [True] * 3
    if orphaned_count > 0:
        print("Mesh parametrization tools: warning, found orphaned faces in mesh.")
    
    return np.array(face_updates, dtype=np.bool)
        

# -----------------------------------------------------------------------------------------

def connections_to_array(connection_list, dtype=np.float64, inverse=True):
    """
    Converts a list of sets of indices that encodes the desired connections into a numpy 
    array that can be used to modify the gradient.  The return is a matrix that can be left
    multiplied onto a vector to implement the desired connections upon update.
    """
    size = len(connection_list)
    array = np.array(
        [[1 if j in row else 0 for j in range(size)] for row in connection_list],
        dtype=dtype
    )
    array += np.eye(size, dtype=dtype)
    if inverse:
        return array
    else:
        return array.T

# =========================================================================================

def visualize_connections(plot, mesh, connection_list, color="yellow"):
    """
    Plots lines on a pyvista plot that visualize a directed graph.  The graph is represented
    by connection_list, which has an element for each vertex in the mesh that contains
    a set of other vertexes to be connected to it.
    """
    start_points = []
    end_points = []
    points = mesh.points
    point_count = points.shape[0]

    for i in range(point_count):
        for connection in connection_list[i]:
            start_points.append(points[i])
            end_points.append(points[connection])
    start_points = np.array(start_points)
    end_points = np.array(end_points)
    
    end_points -= start_points
    
    plot.add_arrows(start_points, end_points, color=color)
    
# -----------------------------------------------------------------------------------------

def visualize_generations(
    plot, mesh, generations, colors=["red", "yellow", "green", "blue", "purple"]
):
    """
    Plots points as colored dots that use color to visualize generations.
    """
    
    colors = itertools.cycle(colors)
    for generation in generations:
        color = next(colors)
        points = np.take(mesh.points, list(generation), axis=0)
        plot.add_mesh(
            pv.PolyData(points),
            color=color,
            point_size=10,
            render_points_as_spheres=True
        )

# -----------------------------------------------------------------------------------------
        
def visualize_face_updates(plot, mesh, face_updates, color="red"):
    start_points = []
    end_points = []
    points = mesh.points
    faces = np.reshape(mesh.faces, (-1, 4))[:,1:]
    face_count = faces.shape[0]
    
    for i in range(face_count):
        if np.any(face_updates[i]):
            face = faces[i]
            vertices = np.take(points, face, axis=0)
            center = np.sum(vertices, axis=0)/3
            movable_vertices = vertices[face_updates[i],:]
            for each in movable_vertices:
                start_points.append(center)
                end_points.append(each - center)
    
    start_points = np.array(start_points)
    end_points = np.array(end_points)            
    plot.add_arrows(start_points, end_points, color=color)
            
# =========================================================================================

def circular_mesh(
    radius,
    target_edge_size,
    starting_radius=0,
    theta_start=0,
    theta_end=2*PI,
    join=None 
):
    """
    Generate a circular mesh that is as uniform as possible.
    
    This function is designed for generating zero point meshes for planar lenses.  It works
    well combined with the FromVectorVG vector generator in boundaries.py.  This function
    is limited: it's output is in the x,y plane, and it is centered at zero, so if that isn't
    what you need, you will have to manually rotate the surface after generating it.  Since
    this function returns a pv.PolyData, it will come with built in transformation commands!
    
    Parameters
    ----------
    radius : float
        The radius of the circle
    target_edge_size : float
        This is approximately how long the edge of each triangle generated by this function
        will be.
    starting_radius : float, optional
        Defaults to zero.  The inner radius of the generated circle.
    theta_start : float, optional
        Defaults to zero.  The angle where the circle starts.
    theta_end : float, optional
        Defaults to 2 PI.  The angle where the circle ends.
    join : bool, optional
        If true, the oppozite sides of the circle will be joined together.  This only makes
        sense for complete circles.  By default the value for this parameter will be inferred
        from theta_start and theta_end, and will default to a joined circle only if the circle
        is complete (i.e. theta_start = 0 and theta_end = 2PI).
        
    Returns
    -------
    A pv.PolyData in the x,y plane, centered at zero.
    
    """
    if join is None:
        join = bool(theta_start==0) and bool(theta_end==2*PI)
        
    if starting_radius >= radius:
        raise ValueError("circular_mesh: starting_radius must be < radius.")
    
    # figure out each radius at which we will place points
    radius_step = target_edge_size * math.sin(PI/3)
    radius_step_count = max(int(1 + (radius - starting_radius) / radius_step), 2)
    radius_steps = np.linspace(starting_radius, radius, radius_step_count)
    
    # Compute the number of trapezoids each layer will be built from.
    # (including possibly the degenerate trapezoid that is actually a triangle at the
    # center of the wedge).
    trapezoid_count = math.ceil((theta_end - theta_start) / (PI/3))
    
    # Compute the number of points along the inner edge of each trapezoid.  This will be
    # 1 if we are starting at radius 0.
    if starting_radius != 0:
        starting_arc_length = radius_steps[0] * (theta_end - theta_start) / trapezoid_count
        trapezoid_inner_edge_count = math.ceil(starting_arc_length / target_edge_size) + 1
    else:
        trapezoid_inner_edge_count = 1
    starting_angles = np.linspace(
        theta_start,
        theta_end,
        (trapezoid_inner_edge_count - 1) * trapezoid_count + 1
    )
    
    # compute the numbers of triangles in each trapezoid, in the first layer
    triangles_per_trapezoid = 2 * trapezoid_inner_edge_count - 1
    
    # start generating the points
    points = [
        (radius_steps[0] * math.cos(angle), radius_steps[0] * math.sin(angle), 0)
        for angle in starting_angles
    ]
    faces = []
    cumulative_point_count = len(points)
    new_point_count = cumulative_point_count
    last_indices = itertools.cycle(range(cumulative_point_count))
    for radius in radius_steps[1:]:
        # generate the new points
        new_points = []
        new_point_count += trapezoid_count
        for angle in np.linspace(theta_start, theta_end, new_point_count):
            new_points.append((radius * math.cos(angle), radius * math.sin(angle), 0))
        if join:
            # if the edges are joined, remove the last point, because it should be equal
            # to the first point.  Since we are using cycle iterators, this happens
            # automatically!
            new_points.pop()
        points += new_points
        
        # create iterator for generating the edges.  I am using a cycling iterator to
        # automatically cover the edge case where we need to join the two sides of
        # the wedge when the circle is full.
        new_indices = itertools.cycle(range(
            cumulative_point_count,
            cumulative_point_count + len(new_points)
        ))
        
        first = next(new_indices)
        second = next(last_indices)
        save_second = second
        for trapezoid in range(trapezoid_count):
            choose_outer = True
            for i in range(triangles_per_trapezoid):
                if choose_outer:
                    third = next(new_indices)
                    faces.append((third, second, first))
                else:
                    third = next(last_indices)
                    faces.append((first, second, third))
                first = second
                save_second = second
                second = third
                choose_outer = not choose_outer
            first = third
            second = save_second
        
        # update for the next loop pass
        last_indices = itertools.cycle(range(
            cumulative_point_count,
            cumulative_point_count + len(new_points)
        ))
        cumulative_point_count += len(new_points)
        triangles_per_trapezoid += 2
        
    # process the shape of the faces
    faces = np.array(faces, dtype=np.int64)
    faces = np.pad(faces, ((0, 0), (1, 0)), mode='constant', constant_values=3)
    faces = np.reshape(faces, (-1))
        
    return pv.PolyData(np.array(points), faces)
    
def hexagonal_mesh(radius=1.0, step_count=10):
    """
    Generate a totally uniform hexagonal mesh out of equilateral triangles.
    
    Parameters
    ----------
    radius : float, optional
        The radius of the hexagon (distance between the center and one of the corners).
        Defaults to 1.0
    step_count : int, optional
        Number of layers of triangles to use.
        Defaults to 10
        
    Returns
    -------
    hexagonal_mesh : pyvista mesh
        The new mesh.
        
    """
    radius_steps = np.linspace(0, radius, step_count+1)
    points = [(0.0, 0.0, 0.0)]
    faces = []
    cumulative_point_count = 1
    new_point_count = 1
    last_indices = itertools.cycle([0])
    
    for radius in radius_steps[1:]:
        # make all of the new points for the entire layer of triangles.
        
        # create the points along each edge of the hex, but skip the last
        trapezoid_edge_points = [
            np.linspace(
                (radius*np.cos(PI/3*trapezoid), radius*np.sin(PI/3*trapezoid), 0.0),
                (radius*np.cos(PI/3*(trapezoid+1)), radius*np.sin(PI/3*(trapezoid+1)), 0.0),
                new_point_count + 1
            )[:-1,:]
            for trapezoid in range(6)
        ]
        
        # concatenate the trapezoid edges into a single set of new points.
        new_points = np.concatenate(trapezoid_edge_points, axis=0)
        points = np.concatenate([points, new_points], axis=0)
        
        # make an iterator for these new points   
        new_indices = itertools.cycle(range(
            cumulative_point_count,
            cumulative_point_count + len(new_points)
        ))
        
        # weave the faces
        first = next(new_indices)
        second = next(last_indices)
        save_second = second
        for trapezoid in range(6):
            choose_outer = True
            for i in range(2 * new_point_count - 1):
                if choose_outer:
                    third = next(new_indices)
                    faces.append((third, second, first))
                else:
                    third = next(last_indices)
                    faces.append((first, second, third))
                first = second
                save_second = second
                second = third
                choose_outer = not choose_outer
            first = third
            second = save_second
            
        # update things for the next layer pass
        last_indices = itertools.cycle(range(
            cumulative_point_count,
            cumulative_point_count + 6 * new_point_count
        ))
        cumulative_point_count += 6 * new_point_count
        new_point_count += 1
            
    # process the shape of the faces
    faces = np.array(faces, dtype=np.int64)
    faces = np.pad(faces, ((0, 0), (1, 0)), mode='constant', constant_values=3)
    faces = np.reshape(faces, (-1))
        
    return pv.PolyData(np.array(points), faces)
        
            
# -------------------------------------------------------------------------------------------

def cylindrical_mesh(
    start,
    end,
    radius=1.0,
    theta_res=6,
    z_res=8,
    start_cap=True,
    end_cap=True,
    use_twist=False,
    epsilion=1e-6
):
    """
    Generate a cylindrical mesh suitable for a parametric surface.
    
    This function is designed to be used to generate a paremtrizable surface that is more 
    like a light guide than a lens.  It generates a cylindrical optic between two points.
    The recommended way to use this is to input the minimum allowed radius for the parametric
    optic, constrain the parameters to zero, and initialize them with some non-zero value, if
    you don't want the optic to start at minimum thickness.
    
    It is recommended to keep both the start and end caps closed, as is default.  This option
    will generate two extra vertices along the axis.  If this surface is used with the
    FromAxisVG vector generator, it should generate zero length vectors for these two
    vertices, and so they should remain immobile, so you don't need to worry about masking them
    out of the gradient calculation.
    
    Parameters
    ----------
    start : float 3-vector
        The point on the axis where the cylinder will start.
    end : float 3-vector
        The point on the axis where the cylinder will end.
    radius : float
        The radius of the cylinder.  A radius of zero is permissible in case that is how
        you want to parametrize things.
    theta_res : int, optional
        The number of points to place around the diameter of the cylinder.  Defaults to 6.
    z_res : int, optional
        The number of points to place along the axis of the cylinder.  Defaults to 8.
    start_cap : bool, optional
        Defaults to True, in which case triangles are generated to close the start of the 
        cylinder.
    end_cap : bool, optional
        Defaults to True, in which case triangles are generated to close the end of the 
        cylinder.
    use_twist : bool, optional
        Defaults to True, in which case the triangles will be twisted around the axis each
        layer.  Does not work well for small angular resolution, but could possibly work better
        at high angular resolutions.
    epsilion : float, optional
        A small value to compare to to detect zero length vectors.  Defaults to 1e-6.
        If the distance between end and start is too small, you may need to reduce the size
        of epsilion.

    Returns
    -------
    The cylindrical mesh, a pv.PolyData.
    
    """
    # reshape everything to (1, 3)
    start = np.reshape(start, (1, 3))
    end = np.reshape(end, (1, 3))
    axis = end - start
    
    # Need to generate two vectors u, v that are perpendicular to each other and to
    # the axis, and whose length is the radius.
    # Do this by first trying axis X x-hat.  If it is nonzero, good; otherwise try axis X y-
    # hat instead.
    u = np.cross(axis, (1.0, 0.0, 0.0))
    u_norm = np.linalg.norm(u)
    if u_norm < epsilion:
        u = np.cross(axis, (0.0, 1.0, 0.0))
        u_norm = np.linalg.norm(u)
    if u_norm < epsilion:
        raise ValueError(
            "cylindrical_mesh: could not find vectors perpendicular to axis.  Try decreasing "
            "epsilion?"
        )
    
    u = u * radius / u_norm
    u = np.reshape(u, (1, 3))
    
    v = np.cross(axis, u)
    v = v * radius / np.linalg.norm(v)
    v = np.reshape(v, (1, 3))
    
    # parametrize is a function that will convert theta and z parameters into points on the
    # surface of the cylinder
    def parametrize(theta, z):
        return start + z * axis + np.cos(theta) * u + np.sin(theta) * v
          
    theta, z = np.meshgrid(np.linspace(0, 2*PI, theta_res+1)[:-1], np.linspace(0, 1, z_res))

    if use_twist:
        # need to twist by half a triangle every layer
        twist = np.reshape(PI / theta_res * np.arange(z_res), (-1, 1))
        theta += twist
    
    # this 3 dimensional array holds all the vertices, except the end caps.  But I want to be 
    # careful about the ordering, so I will reorder this manually as I generate the triangles.
    cylinder_points = parametrize(np.expand_dims(theta, 2), np.expand_dims(z, 2))
    
    points = []
    faces = []
    
    if start_cap:
        points.append(start[0,:])
        start_offset = 1
    else:
        start_offset = 0
    
    for theta in range(theta_res):
        points.append(cylinder_points[0, theta])
        
    if start_cap:
        for theta in range(theta_res):
            faces.append((
                theta + 1,
                0,
                (theta + 1) % theta_res + 1
            ))
        
    for z in range(1, z_res):
        for theta in range(theta_res):
            points.append(cylinder_points[z, theta])
            faces.append((
                (z-1) * theta_res + start_offset + (theta + 1) % theta_res,
                z * theta_res + start_offset + theta,
                (z-1) * theta_res + start_offset + theta
            ))
            faces.append((
                z * theta_res + start_offset + theta,
                (z-1) * theta_res + start_offset + (theta + 1) % theta_res,
                z * theta_res + start_offset + (theta + 1) % theta_res
            ))
            
    if end_cap:
        points.append(end[0,:])
        last_vertex = len(points) - 1
        z_offset = (z_res-1) * theta_res
        if start_cap:
            z_offset += 1
        for theta in range(theta_res):
            faces.append((
                (theta + 1) % theta_res + z_offset,
                last_vertex,
                theta + z_offset
            ))
    
    def pack_faces(faces):
        return np.reshape(np.pad(faces, ((0, 0), (1, 0)), constant_values=3), (-1,))
    
    return pv.PolyData(np.array(points), pack_faces(faces))
    
# ==========================================================================================

def planar_interpolated_remesh(
    input_mesh,
    base_mesh,
    range_axis=2,
    interp_fill_value=0.0,
    flatten=True
):
    """
    Remeshes input_mesh like base_mesh.
    
    This function is designed for re-meshing an initial condition mesh whose vertices define
    the desired shape but are not uniform enough for good optimization.
    
    input_mesh should have extent into all three dimensions, but should be single-valued with
    respect to the interpolation_axis.  A 2D interpolating function will be computed for the 
    height of input_mesh's vertices (along the interpolation axis) and this interpolation will
    be used to set the position of the vertices in base_mesh (by moving them only along the
    interpolation_axis).
    
    base_mesh should be a 3D mesh but confined to the plane not containing the 
    interpolation_axis.  Any data in the interpolation_axis will be ignored.  Typically this
    mesh will be generated from one of the mesh generating functions defined in this module, 
    since they are designed to produce highly regular meshes, though this isn't required.   
    base_mesh will be copied before being used by this function, and so will not be changed.
    
    Parameters
    ----------
    input_mesh : pyvista mesh
        The mesh whose shape to preserve while being re-meshed.
    base_mesh : pyvista mesh
        The mesh to re-mesh like.  Should be a planar mesh with highly uniform triangulation.
    range_axis : int, optional
        Must be in {0, 1, 2} the axis to interpolate over.  Defaults to 2, the z-axis.
    interp_fill_value : float, optional
        Value given to the interpolation function to fill with outside of the domain given
        during interpolation.  Defaults to zero.
    flatten : bool, optional
        Defaults to True, and determines the return type
        
    Returns
    -------
    If flatten is True:
        zero_points : pyvista mesh
            The flattened re-meshed version of input_mesh
        initial_parameters : np.array
            The coordinates along interpolation_axis that will give zero_points the proper
            shape.
    If flatten is False:
        remeshed : pyvista mesh
            The re-meshed version of input_mesh
    """
    
    if range_axis == 0:
        domain_axes = (1, 2)
    elif range_axis == 1:
        domain_axes = (0, 2)
    elif range_axis == 2:
        domain_axes = (0, 1)
    else:
        raise ValueError("planar_interpolated_remesh: axis must be in {0, 1, 2}.")
    
    
    input_range = input_mesh.points[:,range_axis]
    input_domain = input_mesh.points[:,domain_axes]
    
    output_domain = base_mesh.points[:,domain_axes]
    output_range = griddata(
        input_domain,
        input_range,
        output_domain,
        fill_value=interp_fill_value
    )
    
    if flatten:
        output_mesh = base_mesh.copy()
        output_mesh.points[:,range_axis] = 0.0
        return output_mesh, output_range
    else:
        output_mesh = base_mesh.copy()
        output_mesh.points[:,range_axis] = output_range
        return output_mesh


# ===============================================================================

def clean_mesh(mesh, distance_tolerance=1e-6):
    """
    Perform various processes to clean up a pyvista mesh.  It:

    1) triangulates the mesh.
    2) removes duplicated vertices.
    3) removes faces with more than one copy of a vertex
    4) removes duplicated faces.

    Parameters
    ----------
    mesh : pyvista PolyData
        The mesh to clean
    distance_tolerance : optional float
        The minimum distance between vertices before they are considered equivalent and
        deduplicated.

    Returns
    -------
    mesh : pyvista mesh
        The cleaned mesh
    """

    mesh = mesh.triangulate()
    vertices = mesh.points
    faces = np.array(unpack_faces(mesh.faces))

    vertices, faces = clean_mesh_raw(vertices, faces, distance_tolerance)

    return pv.PolyData(vertices, pack_faces(faces))


def clean_mesh_raw(vertices, faces, distance_tolerance=1e-6):
    """
    Perform various processes to clean up a pyvista mesh.  Identical to clean_mesh,
    except this version uses raw arrays for the vertices and faces, rather than
    a pyvista mesh.  This function:

    1) triangulates the mesh.
    2) removes duplicated vertices.
    3) removes faces with more than one copy of a vertex
    4) removes duplicated faces.

    Parameters
    ----------
    vertices : np array
    faces : np array
    distance_tolerance : optional float
        The minimum distance between vertices before they are considered equivalent and
        deduplicated.

    Returns
    -------
    vertices, faces
    """

    # Remove duplicated vertices.
    # Calculate the distance between every pair of vertices to find overlaps
    distance = np.sum((vertices[None, :, :] - vertices[:, None, :]) ** 2, axis=-1)

    # dup_v_pairs will be a bool matrix that encodes where duplicated vertices exist,
    # (by checking the distance between them) but contains every redundant pair.  These
    # redundancies need to be cut down.  We do this by first selecting only the lower triangle
    # out of the matrix, and then figuring out which rows have any true values.  These are the
    # vertices to delete.  For each row/v_to_del we then need to find the first column that is
    # true to get the partner to replace with.
    triangle = np.tril(np.ones_like(distance, dtype=np.bool), k=-1)
    dup_v_pairs = np.logical_and(triangle, distance < distance_tolerance)
    v_to_del = np.nonzero(np.any(dup_v_pairs, axis=1))[0]
    v_repl = np.argmax(dup_v_pairs, axis=1)[v_to_del]

    # Now we need to make all the replacements in the faces array
    for d, r in zip(v_to_del, v_repl):
        faces[faces == d] = r

    # Now delete all duplicated vertices out of the vertex array, and decrement the vertex
    # index of each face wherever indices are higher than the deleted vertex.  This has to be
    # done for every duplicated vertex in order from highest to lowest.
    vertices = np.delete(vertices, v_to_del, axis=0)
    for d in v_to_del[::-1]:
        faces[faces > d] -= 1

    # Remove duplicated faces.
    # This is accomplished via python set operations, which is super convenient, except
    # that this can reorder the vertices within a face, which can flip the norm, which
    # has to be avoided.  So I use both a set to track uniqueness and a list to avoid
    # norm flips.
    faces_set = set()
    faces_list = []
    for face in faces:
        fs = frozenset(face)
        # Ensure that all vertices on the face are unique.
        if len(fs) == 3:
            # If the face is not in the set, then add the original to the list.
            if fs not in faces_set:
                faces_list.append(face)
                faces_set |= {fs}
    faces = np.array(faces_list)

    return vertices, faces


def pack_faces(faces):
    """
    Convert a set of faces (tensor of shape (n, 3)) into the proper format for pymesh:
    each face is prefixed with 3 and the total is flattened.
    """
    faces = np.array(faces, dtype=np.int64)
    return np.reshape(np.pad(faces, ((0, 0), (1, 0)), constant_values=3), (-1,))


def unpack_faces(faces):
    """
    Convert a set of faces from the pymesh format into a 2d array
    (tensor of shape (n, 3)), assuming all faces are triangles.
    """
    return np.reshape(faces, (-1, 4))[:, 1:]












